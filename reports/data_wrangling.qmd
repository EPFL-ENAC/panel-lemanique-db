---
title: "Lemanique Panel - data wrangling"
author: "Hugo Solleder"
date: today
format: 
  html:
    toc: true
    toc-depth: 5
    number-sections: true
    code-summary: "Show the code"
    code-fold: true
    code-block-border-left: true
    embed-resources: true
editor: visual
---

## Summary

This report summarizes the overview of the data currently provided by the LASUR and HERUS labs about the Lemanique Panel.

```{r load-libraries}
#| message: false

library(haven)
library(dplyr)
library(stringr)

folder <- "/Volumes/LASUR/common/LaSUR/06 - Recherche/Dossier de travail IT4R/"
```

## Overview of the data

The data is located in `/Volumes/LASUR/common/LaSUR/06 - Recherche/Dossier de travail IT4R/`. Two waves are currently available

-   Wave 1 - Mobility
-   Wave 2 - Consommation

Additional data (e.g., leisure and GPS tracking will be provided in time)

### Wave 1

```{r load-wave1-data}
#| results: asis
#| code-fold: false
wave1_data <- haven::read_sav(
  file.path(
    folder,
    "Enquête mobilité/EPFL_vague1_pond_clean_240319.sav"
  )
)

```

```{r display-wave1-data}
#| results: asis
#| echo: false

cat(sprintf(
  "The data frame contains %i samples and has %i columns\n",
  nrow(wave1_data),
  ncol(wave1_data)
))

```

### Wave 2

The wave 2 data is located in the `Enquête consommation/Data` subfolder and includes two additional subfolders, `FORS` and `HERUS`. Both subfolders contain an SPSS (`.sav`) file alongside a file in a different format (`.csv` for `FORS`, `.rds` for `HERUS`).

#### FORS

##### SPSS

The SPSS data (`.sav`) can be loaded using the `haven` package

```{r load-fors-spss-data}
#| results: asis
#| code-fold: false
fors_spss_data <- haven::read_sav(
  file.path(
    folder,
    "Enquête consommation/Data/Database from FORS/EPFL Panel LÇmanique Vague 2 _FINAL_EPFL.sav"
  )
)

```

```{r display-fors-spss-data}
#| results: asis
#| echo: false

cat(sprintf(
  "The data frame contains %i samples and has %i columns\n",
  nrow(fors_spss_data),
  ncol(fors_spss_data)
))

```

The data dictionary was probably extracted from SPSS for this file.

##### CSV

```{r load-fors-csv-data}
#| message: false
#| code-fold: false

fors_csv_data <- readr::read_csv2(
  file.path(
    folder,
    "Enquête consommation/Data/Database from FORS/EPFL Panel LÇmanique Vague 2 _FINAL_EPFL.csv"
  ),
  locale = readr::locale(encoding = "latin1"),
  show_col_types = FALSE,
  progress = FALSE
)
```

```{r display-fors-csv-data}
#| results: asis
#| echo: false

cat(sprintf(
  "The data frame contains %i samples and has %i columns\n",
  nrow(fors_csv_data),
  ncol(fors_csv_data)
))

```

##### Comparison

```{r diff-fors-columns}
#| results: asis
#| echo: false

additional_csv_columns <- setdiff(colnames(fors_csv_data), colnames(fors_spss_data))

cat(
  sprintf(
    "The CSV data contains %i more columns than the SPSS data. ",
    length(additional_csv_columns)
  ),
  "Beyond the first column specifying the row number, the four additional columns are the ",
  sprintf("following: `%s`.", stringr::str_c(additional_csv_columns[-1], collapse = "`, `"))
)

```

These four additional columns are documented in the `READ_ME.docx` file, as weighting strategies build by LASUR during Wave 1 and 2. The variables with the `wgt_cant_trim` correspond to a canton- or country-based weighting, whereas `wgt_agg_trim` correspond to an agglomeration-based weighting. Variables ending in `_v2` indicate that this variable was used for the second wave.

Based on the `IDNO` variable, the CSV file in a strict subset of the SPSS file, with all 5534 samples from the SPSS file found in the CSV.

#### HERUS

##### SPSS

In contrast to the FORS data, reading the HERUS data with `heaven` is possible but adds artefacts to the data. Using `foreign` bypasses this issue.

```{r load-herus-spss-data}
#| results: asis
#| code-fold: false

herus_spss_data <- foreign::read.spss(
  file.path(
    folder,
    "Enquête consommation/Data/Database update for report/EPFL Panel LÇmanique Vague 2 _Update_HERUS.sav"
  ),
  use.value.labels = FALSE,
  to.data.frame = TRUE,
  trim_values = TRUE
)

```

```{r display-herus-spss-data}
#| results: asis
#| echo: false

cat(sprintf(
  "The data frame contains %i samples and has %i columns\n",
  nrow(herus_spss_data),
  ncol(herus_spss_data)
))

```

##### RDS

```{r load-herus-rds-data}
#| results: asis
#| code-fold: false

herus_rds_data <- readRDS(
  file.path(
    folder,
    "Enquête consommation/Data/Database update for report/EPFL Panel LÇmanique Vague 2 _Update_HERUS.rds"
  )
)

```

```{r display-herus-rds-data}
#| results: asis
#| echo: false

cat(sprintf(
  "The data frame contains %i samples and has %i columns\n",
  nrow(herus_rds_data),
  ncol(herus_rds_data)
))

```

##### Comparison

The samples IDs (`IDNO`) and variable names are consistent between the SPSS and RDS files.

#### Differences between FORS and HERUS data

```{r diff-wave2-columns}
#| results: asis
#| echo: false

herus_extra_columns <- setdiff(colnames(herus_rds_data), colnames(fors_csv_data))
fors_extra_columns <- setdiff(colnames(fors_csv_data), colnames(herus_rds_data))

cat(
  sprintf(
    "The HERUS data contains %i columns that are not included in the FORS data.",
    length(herus_extra_columns)
  ),
  "The additional columns are the following: ",
  sprintf("\n\n* `%s`\n\n", stringr::str_c(herus_extra_columns, collapse = "`,\n * `"))
)

cat(
  sprintf(
    "The FORS data contains %i columns that are not included in the HERUS data.",
    length(fors_extra_columns)
  ),
  "Beyond the first column indicating the row number, the additional columns are the following: ",
  sprintf("\n\n* `%s`\n", stringr::str_c(fors_extra_columns[-1], collapse = "`,\n * `"))
)

```

Out of the 18 additional columns found in the HERUS data, the `HS_ZONE_C` and `HS_URBANAREA_C` are documented in the `READ_ME.docx` file.

-   `HS_URBANAREA2_C` is an identical copy of `HS_URBANAREA_C` and could be removed.
-   `Pays_cor` is a correction of the `Pays` variable for three samples erroneously identified as `Suisse`
-   `weight_tot` is an undocumented weighting variable
-   `Groupe2` is a variable with a finer granularity than `HS_ZONE_C`
-   `Groupe3` is unclear

The remaining additional variables `LOG_Q7`, `LOG_Q6`, `LOG_Q0`, `ENE_Q0`, `END_Q0`, `END_Q1`, `END_Q3`, `END_Q4`, `END_Q5`, `END_Q6`, `END_Q7` are artefacts due to an erroneous export from SPSS to RDS.

```{r diff-wave2-ids}
#| results: asis
#| echo: false

cat(sprintf(
  "Additionally, the overlap in `IDNO` between the FORS and HERUS data is limited to **%i samples**.",
  length(intersect(herus_spss_data$IDNO, fors_spss_data$IDNO))
))

```

### Questions to answer

```{r questions}

w1_inw2 <- wave1_data |> 
  dplyr::filter(IDNO %in% fors_csv_data$IDNO) |> 
  dplyr::arrange(IDNO)

w2_inw1 <- fors_csv_data |> 
  dplyr::filter(IDNO %in% wave1_data$IDNO) |>  
  dplyr::arrange(IDNO)

w2_notinw1 <- fors_csv_data |> 
  dplyr::filter(IDNO %in% setdiff(IDNO, wave1_data$IDNO)) |>  
  dplyr::arrange(IDNO)

shared_variables <- intersect(colnames(w1_inw2), colnames(w2_inw1))

```

```{r variable_overlap}
#| results: asis
#| echo: false

cat(
  "The following variables are present in both waves: `",
  stringr::str_c(shared_variables, collapse = "`, `" ),
  "`",
  sep = ""
)

is_diagonal <- function(x) {
  sum(abs(x)) == sum(abs(diag(x)))
}

```

-   Identical: `Groupe`, `GP_Age_source`
-   Different: `Pays`, `CP_source`, `Localité_source`, `CP_actuel`, `Localité_atuel`

#### Which dataset is included in which dataset?

Is some data stable over time? There are

#### How was the weighting obtained for the second wave?

```{r weighting-question}

cat(
  sprintf(
    "The largest difference in `wgt_agg_trim` is %.2e.\n", 
    max(abs(w1_inw2$wgt_agg_trim - w2_inw1$wgt_agg_trim))
  ),
  sprintf(
    "The largest difference in `wgt_agg_trim_v2` is %.2e.\n", 
    max(abs(as.numeric(w1_inw2$wgt_agg_trim_v2) - w2_inw1$wgt_agg_trim_v2))
  ),
  sprintf(
    "The largest difference in `wgt_cant_trim` is %.2e.\n",
    max(abs(w1_inw2$wgt_cant_trim - w2_inw1$wgt_cant_trim))
  ),
  sprintf(
    "The largest difference in `wgt_cant_trim_v2` is %.2e.\n", 
    max(abs(as.numeric(w1_inw2$wgt_cant_trim_v2) - w2_inw1$wgt_cant_trim_v2))
  ),
  sep = ""
)

```

Given that all samples in wave 2 have either weighting across the four weighting variables that is either systematically

-   identical to the first wave weighting
-   `NA`

we can conclude that the weighting in the CSV was obtained via a join, or by exactly reproducing the weighting of the first wave.
